{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c2c088",
   "metadata": {},
   "source": [
    "## Project Introduction\n",
    "- The primary goal is to process raw audio inputs and generate sentiment predictions through sequential speech-to-text transcription and sentiment classification.\n",
    "- It aims to establish a modular and scalable architecture capable of integrating multiple ASR and sentiment models.\n",
    "- The objective is to benchmark these model combinations based on accuracy, latency, throughput, and overall efficiency.\n",
    "- Ultimately, it seeks to evolve into an operational and deployable system suitable for real-time audio sentiment analysis.\n",
    "\n",
    "## Group Members\n",
    "- Ziyang Jia\n",
    "- Souvik Bag\n",
    "- Srikar Alla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5501446",
   "metadata": {},
   "source": [
    "## Settings\n",
    "### Models Included\n",
    "1. Audio to Text\n",
    "- AventIQ-AI/whisper-audio-to-text\n",
    "    - Base Architecture: OpenAI Whisper\n",
    "    - Dataset / Fine-Tuning: Mozilla Common Voice 13.0 dataset\n",
    "    - Task / Use-Case: Speech-to-Text (Automatic Speech Recognition, ASR)\n",
    "    - Parameter Size: 72M\n",
    "2. Text to Sentiment\n",
    "- distilbert‑base‑uncased‑finetuned‑sst‑2‑english (Small)\n",
    "    - Base Architecture: DistilBERT‑base‑uncased\n",
    "    - Dataset / Fine-Tuning: Stanford Sentiment Treebank (SST‑2)\n",
    "    - Task / Use-Case: Sentiment Analysis\n",
    "    - Parameter Size: 66M\n",
    "- siebert/sentiment‑roberta‑large‑english (Large)\n",
    "    - Base Architecture: RoBERTa-Large\n",
    "    - Dataset / Fine-Tuning: 15 mixed English sentiment datasets\n",
    "    - Task / Use-Case: Sentiment Analysis\n",
    "    - Parameter Size: 355M\n",
    "- cardiffnlp/twitter‑roberta‑base‑sentiment‑latest (Medium)\n",
    "    - Base Architecture: RoBERTa-Base\n",
    "    - Dataset / Fine-Tuning: 124 M tweets (TweetEval benchmark)\n",
    "    - Task / Use-Case: Sentiment Analysis\n",
    "    - Parameter Size: 125M\n",
    "\n",
    "### Model Variant\n",
    "1. Quantitatively Evaluated \n",
    "- fp32 - audio to text models and text to sentiment models\n",
    "- fp16 - text to sentiment models\n",
    "2. Provided in Web Service (will be quantitatively evaluated in Milestone 3)\n",
    "- fp32 - audio to text models and text to sentiment models\n",
    "- int8 - text to sentiment models\n",
    "\n",
    "### Model Storage\n",
    "- MinIO\n",
    "    - An open-source, high-performance object storage server compatible with Amazon S3 APIs.\n",
    "    - Usage in this pipeline: Store our models in ONNX\n",
    "\n",
    "### Temporal File Storage\n",
    "- Redis\n",
    "    - A high-speed, in-memory key-value store that can act as a cache, database, or message broker.\n",
    "    - Usage in this pipeline: Cache frequent inference results to reduce model load.\n",
    "\n",
    "### Web Server\n",
    "- FastAPI\n",
    "    - A lightweight, asynchronous web framework built on Starlette (for async I/O) and Pydantic (for data validation).\n",
    "    - Usage in this pipeline: deploy docker containers as web service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625c384",
   "metadata": {},
   "source": [
    "## Flexible Container-Based Web Service:\n",
    "- We kept both audio-to-text and text-to-sentiment models as flexible options when we create a container\n",
    "- We assigned different ports to different model combinations\n",
    "- Example:\n",
    "  - input: .wav file\n",
    "  - output:\n",
    "    - transcripted text\n",
    "    - sentiment classification\n",
    "    - inference time\n",
    "\n",
    "![container](https://github.com/Tristan-J/temp/blob/main/Mizzou/25fall/eeml/ms_2/container_3.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6241dbe",
   "metadata": {},
   "source": [
    "## Evaluation Plots\n",
    "![1-2](https://github.com/Tristan-J/temp/blob/main/Mizzou/25fall/eeml/ms_2/eval.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46b864",
   "metadata": {},
   "source": [
    "In the plots above, we used the same audio-to-text model(AventIQ-AI/whisper-audio-to-text fp32) and different vairants of text-to-sentiment models:\n",
    "- M1: distilbert‑base‑uncased‑finetuned‑sst‑2‑english (fp32)\n",
    "- M2: distilbert‑base‑uncased‑finetuned‑sst‑2‑english (fp16)\n",
    "- M3: siebert/sentiment‑roberta‑large‑english (fp32)\n",
    "- M4: siebert/sentiment‑roberta‑large‑english (fp16)\n",
    "- M5: cardiffnlp/twitter‑roberta‑base‑sentiment‑latest (fp32)\n",
    "- M6: cardiffnlp/twitter‑roberta‑base‑sentiment‑latest (fp16)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb41bd",
   "metadata": {},
   "source": [
    "![comparision table](https://github.com/Tristan-J/temp/blob/main/Mizzou/25fall/eeml/ms_2/table.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d6a57",
   "metadata": {},
   "source": [
    "## Empirical Conclusions:\n",
    "- the differences on precision (fp32 vs fp16) \n",
    "    - dosen't impact too much in terms of accuracy and throughput\n",
    "    - impacts more on inference latency\n",
    "- the model structure impacts more on temporal efficiency, e.g. given acc=0.93 and 0.97 for M1(fp16) and M3(fp16), we found that\n",
    "    - the latency of M1 is only around 1/4 of M3\n",
    "    - the throughput of M3 is only 1/4 of M1\n",
    "    - this observation holds for other comparison pairs as well\n",
    "- the model structure impacts more on accuracy as well, e.g. given parameter_size=66M and 125M for M1(fp16) and M5(fp16), the temporal efficiency pattern still holds but we found:\n",
    "    - the accuracy of M1 is more than twice of M5's accuracy\n",
    "- some conclusions in model selection and optimization:\n",
    "    - some model structure+pretrained dataset settings inherently get better accuracies in sentiment classification\n",
    "    - precision impacts the accuracy but the difference is trivial in this task and in real-world applications, fp16 is more promising than the original fp32 models (in terms of temporal efficiency)\n",
    "- inspirations for our future plan in milestone 3: we'll\n",
    "    - push the temporal efficiency further to explore the capability of int8 models \n",
    "    - try more flexible strategies for model choosing given different input (will consider some features like size of the input audio)\n",
    "    - provide an interative webpage if time permits"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
