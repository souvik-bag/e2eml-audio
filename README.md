# Audio Sentiment Analysis pipeline

Here we will build a pipeline with two steps, audio to text conversion and text
sentiment analysis.

You are encouraged to search for more models that are suitable for each task on your own.

## Step 1: Audio to Text

To convert the given audio files you will need to learn about speech to text conversion.
A tutorial on the same can be found here: 
https://www.geeksforgeeks.org/deep-learning/pytorch-for-speech-recognition/?utm_source=chatgpt.com

A more detailed documentation of Speech to Text models on HuggingFace can be found here:
https://huggingface.co/docs/transformers/model_doc/speech_to_text?utm_source=chatgpt.com

Here are two models that can be found on huggingface that can do audio to text conversion:

1. AventIQ-AI/whisper-audio-to-text
2. facebook/s2t-small-librispeech-asr

## Step 2: Text Sentiment Analysis

To perform sentiment analysis on the text generated by the previous step, you are tasked
to employ a pretrained BERT based model that is used for sentiment analysis.

Here are three models that you can find on HuggingFace that can do the same:

1. siebert/sentiment-roberta-large-english
2. cardiffnlp/twitter-roberta-base-sentiment-latest
3. tabularisai/multilingual-sentiment-analysis

## Assertions

As an example, we provide the simple assertion to check if the confidence of the text
sentiment analysis model is above a certain threshold.

## Dataset

For this pipeline we give you a dataset which is the ```DynamicSuperb/Sentiment_Analysis_SLUE-VoxCeleb```
dataset which can be found on HuggingFace.

To use the audio files from the dataset you will have to print out the dataset and extract the array field
to use the audio files.

## Sample
In the container, there is a sample notebook that has some sample code on loading the dataset
and example models.